{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Perceptual evaluation of Saraga-Carnatic-Melody-Synth ground-truth\n",
    "\n",
    "This notebook is meant to perceptually evaluate the vocal melody ground-truth that we have generated within the framework in this repository. The aim of this notebook is to validate, by active listening, that the annotations are actually correct so that they can be considered as ground-truth, and also to detect errors and danger zones, if any, in the annotated data.\n",
    "\n",
    "Make sure you have created the mapping from dataset songs to available ID's. The function to generate the mapping is in the file `utils.py`. You can fastly run this function by running `python3 utils.py`. Make sure the Saraga Carnatic 1.5 path is correctly set up in `config.py`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import glob\n",
    "import math\n",
    "import itertools\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pprint import pprint\n",
    "\n",
    "from pathlib import Path\n",
    "from scipy.io import wavfile\n",
    "import sounddevice as sd\n",
    "\n",
    "from listening_evaluation_utils import get_dataset_mapping, synthesize_f0, get_audio_mono, play_output_mix\n",
    "\n",
    "path_to_dataset = os.path.join(Path().absolute(), 'resources', 'Saraga-Carnatic-Melody-Synth')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Obtaining and visualize mapping of the songs and related ids."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_mapping = get_dataset_mapping(path_to_dataset)\n",
    "pprint(dataset_mapping.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Print related ID's for certain recording name."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Define here the song you want to hear\n",
    "song = 'Dudukugala'\n",
    "\n",
    "print('Available ids for chosen song:', dataset_mapping[song])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Selecting the track to listen to. The track is loaded."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Define here the ID you want to hear\n",
    "track_id = '1830'\n",
    "\n",
    "samplerate, data = get_audio_mono(path_to_dataset, song, track_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Synthesize the f0 annotation of the related track (SynthSineWave function from sms-tools is used).\n",
    "\n",
    "**RECOMMENDED ATTENUATIONS:**\n",
    "- If center=False: attentuation should be around 0.15 **(please do not exceed 0.2)**\n",
    "- If center=True: attentuation should be around 0.6 **(please do not exceed 0.65)**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "attenuation = 0.15  # BE CAREFUL: Pure tones damage your ear if reproduced too loud!!!\n",
    "f0_synth = synthesize_f0(song, track_id, attenuation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now play the \"mix\", in which the audio signal is reproduced in the left ear and the annotation is reproduced in the right ear. The idea is to try to identify errors and also validate that the annotation can be considered ground truth for vocal melody."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "play_output_mix(data, f0_synth, samplerate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alternatively, you can also play both elements one on top of the other in the center.\n",
    "We first need to resinthesize the f0 to a higher volume so we can hear it above the IAM audio signal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "attenuation = 0.6  # BE CAREFUL: Pure tones damage your ear if reproduced too loud!!!\n",
    "f0_synth = synthesize_f0(song, track_id, attenuation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "play_output_mix(data, f0_synth, samplerate, center=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here you are!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
